
# Introduction

## Concerns

Concerns about confidentiality in statistical products have increased in the past several years:

- New disclosure avoidance techniques in the Decennial Census garnered much attention (an understatement...), 
- also concerns about formal disclosure avoidance techniques for public-use microdata files (PUMFs) (see [Census Bureau delayed implementation of such methods for the American Community Survey](https://www.census.gov/newsroom/blogs/random-samplings/2022/12/disclosure-avoidance-protections-acs.html))

## Creating synthetic data

- Much effort put into creating privacy-protected or synthetic data (this conference!)
- Goal of each of these: **release and forget**

> But what if users donÂ´t trust the data?

## Direct access

- Many different RDC-style systems have been stood up over the past 35+ years in multiple countries
- Provide direct access to confidential (pseudonymous) data
- Still need output disclosure avoidance measures (mostly ad-hoc)
- Expensive for stat agencies to maintain, expensive for users to use

---

> Alternative: validate analyses run on synthetic data against the confidential data

## Validation and Verification

- long-running pilot projects with (non-formal) synthetic microdata products (SynLBD, SIPP Synthetic Beta) came to an end in 2022 ([End of life for the Cornell Synthetic Data Server September 30, 2022](https://web.archive.org/web/20230602202220/https://web.archive.org/web/20221130032540/https://www2.vrdc.cornell.edu/news/))
- not sure how active OPM Verification server was (Barrientos et al (2018))
- scale an issue
- not done or planned for most synthetic data products

## Scaling up

These pilot projects were not set up to scale, and yet they demonstrated that there is a need for such a process. 

